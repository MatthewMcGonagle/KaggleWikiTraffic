{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The idea is to do a simple linear model of non-linear interactions between basic statistics. We will motivate these\n",
    "# interactions based on some intuitions. For example, (mean / std) should influence the forecasting ability \n",
    "# different statistics, i.e. look at (mean / std) * mean. However, we do this for windows.\n",
    "\n",
    "# A better basis is based on using r_i = (mean_window_i / mean_all) or r_i = (mean_window_i / (epsilon + mean_all)).\n",
    "# Normally, one could estimate using the average of the mean_window_i (or some weighted average). However, when \n",
    "# r_i is large, one wants to replace mean_window_i by mean_all. So we are lead to trying basis functions such as\n",
    "# f_i = exp(-K_i * r_i) * mean_window_i + (1 - exp(-K_i * r_i)) * mean_all, where K_i is a constant parameter that\n",
    "# can be adjusted. First try finding optimal K_i that increase linear correlation between Y_mean and f_i.\n",
    "# Also can try using logit functions of r_i or some other functions that is suggestive of a neural network.\n",
    "\n",
    "# Note that key_1.csv shows that we are supposed to predict about 2 months worth of future data based on data\n",
    "# lasting from 2015-07-01 to 2016-12-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score)\n",
    "from sklearn.preprocessing import (PolynomialFeatures, FunctionTransformer, StandardScaler)\n",
    "from sklearn.pipeline import (make_pipeline, make_union, Pipeline, FeatureUnion)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnUNOIv+pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23986ac70b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reference for performace measured by reference function. For a term |y_test - y_predict| / (|y_test| + |y_predict|) * 2 * 100,\n",
    "# we look at when y_predict = alpha * y_test. Look at term as a function of alpha.\n",
    "\n",
    "alpha = np.arange(0.0, 6.0, 0.1)\n",
    "num = np.abs(1 - alpha)\n",
    "denom = 1 + np.abs(alpha)\n",
    "smapeVals = num / denom * 2 * 100\n",
    "\n",
    "plt.plot(alpha, smapeVals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145063, 551)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv('train_1.csv')\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now, just set all NaN to 0.\n",
    "\n",
    "all_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "futureT = 64\n",
    "\n",
    "X_all = all_df.drop('Page', axis = 1).values[:, :-futureT]\n",
    "Y_all = all_df.drop('Page', axis = 1).values[:, -futureT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape =  (65118, 486) \tX_valid.shape =  (32074, 486) \tX_test.shape =  (47871, 486)\n",
      "Y_train.shape =  (65118, 64) \tY_valid.shape =  (32074, 64) \tY_test.shape =  (47871, 64)\n"
     ]
    }
   ],
   "source": [
    "X_trainvalid, X_test, Y_trainvalid, Y_test = train_test_split(X_all, Y_all, test_size = 0.33, random_state = 32)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_trainvalid, Y_trainvalid, test_size = 0.33, random_state = 35)\n",
    "\n",
    "print('X_train.shape = ', X_train.shape, '\\tX_valid.shape = ', X_valid.shape, '\\tX_test.shape = ', X_test.shape)\n",
    "print('Y_train.shape = ', Y_train.shape, '\\tY_valid.shape = ', Y_valid.shape, '\\tY_test.shape = ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(Y_predict, Y_test):\n",
    "    result = np.linalg.norm(Y_predict - Y_test, axis = 1)\n",
    "    result = np.abs(result)\n",
    "    denom = np.linalg.norm(Y_predict, axis = 1)\n",
    "    denom += np.linalg.norm(Y_test, axis = 1)\n",
    "    result /= denom\n",
    "    result *= 100 * 2\n",
    "    result = np.mean(result)\n",
    "    return result\n",
    "\n",
    "def smape_scorer(estimator, X, Y):\n",
    "    Ypredict = estimator.predict(X)\n",
    "    result = smape(Y, Ypredict)\n",
    "    return -result\n",
    "\n",
    "def window_features(X, nWindows = 2, windowSize = 64):\n",
    "    nSamples, nFeatures = X.shape\n",
    "    # Make a view from X that is a 3d array of size (nSamples, windowSize, nWindows). This gives a view\n",
    "    # of each window in X.\n",
    "    X_window = nFeatures - 1 - np.arange(windowSize)[:, np.newaxis] - windowSize * np.arange(nWindows)\n",
    "    X_window = X[:, X_window]\n",
    "    \n",
    "    # Now extract features for X and for each window.\n",
    "    all_mean = np.mean(X, axis = 1, keepdims = True)\n",
    "    features = all_mean.copy()\n",
    "    newCols = np.mean(X_window, axis = 1) # window means\n",
    "    features = np.hstack((features, newCols))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def window_weights(all_mean, window_means, k = 0.4, epsilon = 1e-6):\n",
    "    weights = window_means / (epsilon + all_mean)\n",
    "    weights = np.exp(-k * weights)\n",
    "    return weights\n",
    "    \n",
    "def all_features(X, nWindows = 2, windowSize = 240, k = 0.4, epsilon = 1e-4):\n",
    "    nSamples, nTimes = X.shape\n",
    "    windFeatures = window_features(X, nWindows, windowSize)\n",
    "    weights = window_weights(windFeatures[:,0].reshape(-1,1), windFeatures[:, 1:1+nWindows], k, epsilon)\n",
    "    weightedFeatures = windFeatures[:, :, np.newaxis] * weights[:, np.newaxis, :]\n",
    "    weightedFeatures = weightedFeatures.reshape(nSamples, -1)\n",
    "    windFeatures = np.hstack((windFeatures, weightedFeatures))\n",
    "    return windFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newFeatures.shape =  (65118, 3) \tweights.shape =  (65118, 2) \tallFeatures.shape =  (65118, 9)\n"
     ]
    }
   ],
   "source": [
    "# Look at feature data.\n",
    "\n",
    "newFeatures = window_features(X_train)\n",
    "weights = window_weights(newFeatures[:, 0].reshape(-1,1), newFeatures[:, 1:3])\n",
    "allFeatures = all_features(X_train)\n",
    "print('newFeatures.shape = ', newFeatures.shape, '\\tweights.shape = ', weights.shape, '\\tallFeatures.shape = ', allFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97192, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFVCAYAAACq3jXbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23986aef8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at linear correlations.\n",
    "nSamples, nTimes = X_trainvalid.shape\n",
    "Y_mean = Y_trainvalid.mean(axis = 1, keepdims = True)\n",
    "newFeatures = window_features(X_trainvalid)\n",
    "weights = window_weights(newFeatures[:, 0].reshape(-1,1), newFeatures[:, 1:3])\n",
    "weightFeatures = newFeatures[:, :, np.newaxis] * weights[:, np.newaxis, :]\n",
    "weightFeatures = weightFeatures.reshape((nSamples, -1))\n",
    "print(weightFeatures.shape)\n",
    "corr_vars = np.hstack((Y_mean, newFeatures, weightFeatures)).T\n",
    "corr_names = ['Y', 'allM', 'M1', 'M2', 'allMW1', 'M1W1', 'M2W1', 'AllMW2', 'M1W2', 'M2W2']\n",
    "corr_matrix = np.corrcoef(corr_vars)\n",
    "sns.heatmap(corr_matrix, xticklabels = corr_names, yticklabels = corr_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just window features:\n",
      "Cross val score =  120.346772537 +- 3.87707278018\n",
      "Including weighted window features:\n",
      "Cross val score =  132.22893965 +- 2.49743869974\n",
      "Including weighted window features:\n",
      "Cross val score =  130.760295278 +- 1.01899966725\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at a simple linear models.\n",
    "\n",
    "# First just the window features.\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(window_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "scores = - cross_val_score(model, X_trainvalid, Y_trainvalid, scoring = smape_scorer)\n",
    "print('Just window features:\\nCross val score = ', scores.mean(), '+-', scores.std())\n",
    "\n",
    "# Now weighted features.\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "scores = - cross_val_score(model, X_trainvalid, Y_trainvalid, scoring = smape_scorer)\n",
    "print('Including weighted window features:\\nCross val score = ', scores.mean(), '+-', scores.std())\n",
    "\n",
    "# Now just use high linear correlations.\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('highcorr', FunctionTransformer(lambda X: X[:, [0,1,2,3,5,6,7,8]])),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "scores = - cross_val_score(model, X_trainvalid, Y_trainvalid, scoring = smape_scorer)\n",
    "print('Including weighted window features:\\nCross val score = ', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ,6 ,11 ,16 ,"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f6d5473cde71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre__kw_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'k'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_trainvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_trainvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmape_scorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msearch_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Matthew\\Miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, y, func, kw_args)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         return func(X, *((y,) if self.pass_y else ()),\n\u001b[1;32m---> 94\u001b[1;33m                     **(kw_args if kw_args else {}))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-23ae220d06ec>\u001b[0m in \u001b[0;36mall_features\u001b[1;34m(X, nWindows, windowSize, k, epsilon)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnWindows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindowSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mnSamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnTimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mwindFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnWindows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindFeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindFeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnWindows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mweightedFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindFeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-23ae220d06ec>\u001b[0m in \u001b[0;36mwindow_features\u001b[1;34m(X, nWindows, windowSize)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# of each window in X.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mX_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnFeatures\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindowSize\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnWindows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mX_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_window\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Now extract features for X and for each window.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now let's try varying the size of k associated to the weights.\n",
    "\n",
    "ks = np.arange(1, 30, 5)\n",
    "ks = np.hstack((ks, np.arange(6, 16)))\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for k in ks:\n",
    "    model.set_params(pre__kw_args = {'k' : k})\n",
    "    scores = - cross_val_score(model, X_trainvalid, Y_trainvalid, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(k, ',', end = '')\n",
    "    \n",
    "plt.scatter(ks, search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try varying the size of k associated to the weights.\n",
    "\n",
    "ks = np.arange(0, 1.5, 0.05)\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for k in ks:\n",
    "    model.set_params(pre__kw_args = {'k' : k})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(k, ',', end = '')\n",
    "    \n",
    "plt.scatter(ks, search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try varying the size of k associated to the weights with more windows.\n",
    "\n",
    "ks = np.arange(0, 1.5, 0.05)\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for k in ks:\n",
    "    model.set_params(pre__kw_args = {'k' : k, 'nWindows' : 6})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(k, ',', end = '')\n",
    "    \n",
    "plt.scatter(ks, search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try varying numer of windows and window size.\n",
    "\n",
    "nWindows = np.arange(1, 4, 1)\n",
    "sizes = np.arange(64, 64 * 6, 64)\n",
    "search_space = [(x, y) for x in nWindows for y in sizes]\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for nWindow, size in search_space:\n",
    "    model.set_params(pre__kw_args = {'nWindows' : nWindow, 'windowSize' : size})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(nWindow, ',', size, '** ', end = '')\n",
    "    \n",
    "plt.scatter(np.arange(len(search_scores)), search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters at ', search_space[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vary number of nWindows while making window size be as large as possible\n",
    "\n",
    "nWindows = np.arange(2, 12, 1)\n",
    "sizes = (nTimes / nWindows).astype('int')\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for nWindow, size in zip(nWindows, sizes):\n",
    "    model.set_params(pre__kw_args = {'nWindows' : nWindow, 'windowSize' : size})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(nWindow, ',', size, '** ', end = '')\n",
    "    \n",
    "plt.scatter(np.arange(len(search_scores)), search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's search on window size for nWindows = 2.\n",
    "\n",
    "sizes = np.arange(240, 270, 1)\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for size in sizes:\n",
    "    model.set_params(pre__kw_args = {'nWindows' : 2, 'windowSize' : size})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(size, ' ', end = '')\n",
    "    \n",
    "plt.scatter(sizes, search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's search on window size for nWindows = 2.\n",
    "\n",
    "sizes = np.arange(240, 260, 1)\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "search_scores = np.empty(0)\n",
    "for size in sizes:\n",
    "    model.set_params(pre__kw_args = {'nWindows' : 3, 'windowSize' : size})\n",
    "    scores = - cross_val_score(model, X_train, Y_train, scoring = smape_scorer)\n",
    "    search_scores = np.hstack((search_scores, scores.mean()))\n",
    "    print(size, ' ', end = '')\n",
    "    \n",
    "plt.scatter(sizes, search_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'windowSize': 60, 'nWindows': 4, 'k': 1} 129.215955782\n",
      "0 {'windowSize': 110, 'nWindows': 4, 'k': 1} 136.088158457\n",
      "0 {'windowSize': 110, 'nWindows': 3, 'k': 1} 133.326681454\n",
      "0 {'windowSize': 110, 'nWindows': 4, 'k': 1} 136.088158457\n",
      "0 {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "Best Score  {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "change =  {'windowSize': 46, 'nWindows': 1, 'k': 0.93303299153680741}\n",
      "1 {'windowSize': 64, 'nWindows': 3, 'k': 2.0} 136.263744364\n",
      "1 {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "1 {'windowSize': 110, 'nWindows': 2, 'k': 2.0} 132.291386751\n",
      "1 {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "1 {'windowSize': 110, 'nWindows': 3, 'k': 1.0669670084631926} 133.790536366\n",
      "1 {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "Best Score  {'windowSize': 110, 'nWindows': 3, 'k': 2.0} 132.368431689\n",
      "change =  {'windowSize': 42, 'nWindows': 1, 'k': 0.87055056329612412}\n",
      "2 {'windowSize': 68, 'nWindows': 3, 'k': 2.0} 139.040292059\n",
      "2 {'windowSize': 152, 'nWindows': 3, 'k': 2.0} 132.459006748\n",
      "2 {'windowSize': 152, 'nWindows': 2, 'k': 2.0} 127.46593441\n",
      "2 {'windowSize': 152, 'nWindows': 3, 'k': 2.0} 132.459006748\n",
      "2 {'windowSize': 152, 'nWindows': 2, 'k': 1.1294494367038759} 131.007455389\n",
      "2 {'windowSize': 152, 'nWindows': 2, 'k': 2.0} 127.46593441\n",
      "Best Score  {'windowSize': 152, 'nWindows': 2, 'k': 2.0} 127.46593441\n",
      "change =  {'windowSize': 39, 'nWindows': 1, 'k': 0.81225239635623547}\n",
      "3 {'windowSize': 113, 'nWindows': 2, 'k': 2.0} 132.179862608\n",
      "3 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "3 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "3 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "3 {'windowSize': 191, 'nWindows': 2, 'k': 1.1877476036437646} 132.800785623\n",
      "3 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 36, 'nWindows': 1, 'k': 0.75785828325519899}\n",
      "4 {'windowSize': 155, 'nWindows': 2, 'k': 2.0} 127.744707661\n",
      "4 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "4 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "4 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "4 {'windowSize': 191, 'nWindows': 1, 'k': 1.242141716744801} 128.57785739\n",
      "4 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "Best Score  {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "change =  {'windowSize': 33, 'nWindows': 1, 'k': 0.70710678118654746}\n",
      "5 {'windowSize': 158, 'nWindows': 1, 'k': 2.0} 127.596953627\n",
      "5 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "5 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "5 {'windowSize': 191, 'nWindows': 2, 'k': 1.2928932188134525} 132.454058491\n",
      "5 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 30, 'nWindows': 1, 'k': 0.6597539553864471}\n",
      "6 {'windowSize': 161, 'nWindows': 2, 'k': 2.0} 128.388222025\n",
      "6 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "6 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "6 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "6 {'windowSize': 191, 'nWindows': 1, 'k': 1.3402460446135529} 128.602471005\n",
      "6 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "Best Score  {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "change =  {'windowSize': 27, 'nWindows': 1, 'k': 0.61557220667245816}\n",
      "7 {'windowSize': 164, 'nWindows': 1, 'k': 2.0} 127.981404412\n",
      "7 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "7 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "7 {'windowSize': 191, 'nWindows': 1, 'k': 1.384427793327542} 128.611476227\n",
      "7 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "Best Score  {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "change =  {'windowSize': 25, 'nWindows': 1, 'k': 0.57434917749851755}\n",
      "8 {'windowSize': 166, 'nWindows': 1, 'k': 2.0} 128.043520849\n",
      "8 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "8 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "8 {'windowSize': 191, 'nWindows': 2, 'k': 1.4256508225014826} 132.112922226\n",
      "8 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 23, 'nWindows': 1, 'k': 0.53588673126814668}\n",
      "9 {'windowSize': 168, 'nWindows': 2, 'k': 2.0} 131.9983183\n",
      "9 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "9 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "9 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "9 {'windowSize': 191, 'nWindows': 2, 'k': 1.4641132687318534} 132.029033109\n",
      "9 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 21, 'nWindows': 1, 'k': 0.50000000000000011}\n",
      "10 {'windowSize': 170, 'nWindows': 2, 'k': 2.0} 132.041371278\n",
      "10 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "10 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "10 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "10 {'windowSize': 191, 'nWindows': 1, 'k': 1.5} 128.628224177\n",
      "10 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "Best Score  {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "change =  {'windowSize': 19, 'nWindows': 1, 'k': 0.46651649576840382}\n",
      "11 {'windowSize': 172, 'nWindows': 1, 'k': 2.0} 128.199411944\n",
      "11 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "11 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "11 {'windowSize': 191, 'nWindows': 2, 'k': 1.5334835042315962} 131.890431685\n",
      "11 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 17, 'nWindows': 1, 'k': 0.43527528164806217}\n",
      "12 {'windowSize': 174, 'nWindows': 2, 'k': 2.0} 132.126732303\n",
      "12 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "12 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "12 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "12 {'windowSize': 191, 'nWindows': 2, 'k': 1.5647247183519379} 131.832459767\n",
      "12 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 15, 'nWindows': 1, 'k': 0.40612619817811785}\n",
      "13 {'windowSize': 176, 'nWindows': 2, 'k': 2.0} 132.118571618\n",
      "13 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "13 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "13 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "13 {'windowSize': 191, 'nWindows': 2, 'k': 1.5938738018218821} 131.780440835\n",
      "13 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 13, 'nWindows': 1, 'k': 0.37892914162759961}\n",
      "14 {'windowSize': 178, 'nWindows': 2, 'k': 2.0} 131.988225864\n",
      "14 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "14 {'windowSize': 191, 'nWindows': 1, 'k': 2.0} 128.59910147\n",
      "14 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "14 {'windowSize': 191, 'nWindows': 2, 'k': 1.6210708583724003} 131.733484009\n",
      "14 {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "Best Score  {'windowSize': 191, 'nWindows': 2, 'k': 2.0} 131.154808229\n",
      "change =  {'windowSize': 12, 'nWindows': 1, 'k': 0.35355339059327384}\n",
      "15 {'windowSize': 179, 'nWindows': 2, 'k': 2.0} 132.084183039\n",
      "15 {'windowSize': 203, 'nWindows': 2, 'k': 2.0} 125.78267363\n",
      "15 {'windowSize': 203, 'nWindows': 1, 'k': 2.0} 128.09190262\n",
      "15 {'windowSize': 203, 'nWindows': 2, 'k': 2.0} 125.78267363\n",
      "15 {'windowSize': 203, 'nWindows': 2, 'k': 1.646446609406726} 126.079134392\n",
      "15 {'windowSize': 203, 'nWindows': 2, 'k': 2.0} 125.78267363\n",
      "Best Score  {'windowSize': 203, 'nWindows': 2, 'k': 2.0} 125.78267363\n",
      "change =  {'windowSize': 11, 'nWindows': 1, 'k': 0.32987697769322366}\n",
      "16 {'windowSize': 192, 'nWindows': 2, 'k': 2.0} 130.769296449\n",
      "16 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "16 {'windowSize': 214, 'nWindows': 1, 'k': 2.0} 128.282124418\n",
      "16 {'windowSize': 214, 'nWindows': 2, 'k': 1.6701230223067762} 126.261003671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "change =  {'windowSize': 10, 'nWindows': 1, 'k': 0.30778610333622913}\n",
      "17 {'windowSize': 204, 'nWindows': 2, 'k': 2.0} 125.823231933\n",
      "17 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "17 {'windowSize': 214, 'nWindows': 1, 'k': 2.0} 128.282124418\n",
      "17 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "17 {'windowSize': 214, 'nWindows': 2, 'k': 1.692213896663771} 126.238995034\n",
      "17 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "change =  {'windowSize': 9, 'nWindows': 1, 'k': 0.28717458874925883}\n",
      "18 {'windowSize': 205, 'nWindows': 2, 'k': 2.0} 125.816104029\n",
      "18 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "18 {'windowSize': 214, 'nWindows': 1, 'k': 2.0} 128.282124418\n",
      "18 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "18 {'windowSize': 214, 'nWindows': 2, 'k': 1.7128254112507411} 126.217959003\n",
      "18 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "change =  {'windowSize': 8, 'nWindows': 1, 'k': 0.26794336563407334}\n",
      "19 {'windowSize': 206, 'nWindows': 2, 'k': 2.0} 125.687571286\n",
      "19 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "19 {'windowSize': 214, 'nWindows': 1, 'k': 2.0} 128.282124418\n",
      "19 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "19 {'windowSize': 214, 'nWindows': 2, 'k': 1.7320566343659267} 126.197919152\n",
      "19 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "change =  {'windowSize': 7, 'nWindows': 1, 'k': 0.25000000000000006}\n",
      "20 {'windowSize': 207, 'nWindows': 2, 'k': 2.0} 125.733799431\n",
      "20 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "20 {'windowSize': 214, 'nWindows': 1, 'k': 2.0} 128.282124418\n",
      "20 {'windowSize': 214, 'nWindows': 2, 'k': 2.0} 125.892389371\n",
      "20 {'windowSize': 214, 'nWindows': 2, 'k': 1.75} 126.178883229\n",
      "20 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 6, 'nWindows': 1, 'k': 0.23325824788420191}\n",
      "21 {'windowSize': 208, 'nWindows': 2, 'k': 2.25} 125.525817671\n",
      "21 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "21 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "21 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "21 {'windowSize': 214, 'nWindows': 2, 'k': 2.0167417521157982} 125.872695876\n",
      "21 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 5, 'nWindows': 1, 'k': 0.21763764082403109}\n",
      "22 {'windowSize': 209, 'nWindows': 2, 'k': 2.25} 125.521668694\n",
      "22 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "22 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "22 {'windowSize': 214, 'nWindows': 2, 'k': 2.032362359175969} 125.854366923\n",
      "22 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 4, 'nWindows': 1, 'k': 0.20306309908905892}\n",
      "23 {'windowSize': 210, 'nWindows': 2, 'k': 2.25} 125.560377714\n",
      "23 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "23 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "23 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "23 {'windowSize': 214, 'nWindows': 2, 'k': 2.046936900910941} 125.837319421\n",
      "23 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 3, 'nWindows': 1, 'k': 0.1894645708137998}\n",
      "24 {'windowSize': 211, 'nWindows': 2, 'k': 2.25} 125.592947642\n",
      "24 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "24 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "24 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "24 {'windowSize': 214, 'nWindows': 2, 'k': 2.0605354291862001} 125.82147186\n",
      "24 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 2, 'nWindows': 1, 'k': 0.17677669529663692}\n",
      "25 {'windowSize': 212, 'nWindows': 2, 'k': 2.25} 125.591263348\n",
      "25 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "25 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "25 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "25 {'windowSize': 214, 'nWindows': 2, 'k': 2.073223304703363} 125.806745311\n",
      "25 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.16493848884661183}\n",
      "26 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "26 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "26 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "26 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "26 {'windowSize': 214, 'nWindows': 2, 'k': 2.0850615111533881} 125.793064096\n",
      "26 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.15389305166811457}\n",
      "27 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "27 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "27 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "27 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "27 {'windowSize': 214, 'nWindows': 2, 'k': 2.0961069483318853} 125.780356212\n",
      "27 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.14358729437462942}\n",
      "28 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "28 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "28 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "28 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "28 {'windowSize': 214, 'nWindows': 2, 'k': 2.1064127056253708} 125.76855357\n",
      "28 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.13397168281703667}\n",
      "29 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "29 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "29 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "29 {'windowSize': 214, 'nWindows': 2, 'k': 2.1160283171829635} 125.757592092\n",
      "29 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.12500000000000003}\n",
      "30 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "30 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "30 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "30 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "30 {'windowSize': 214, 'nWindows': 2, 'k': 2.125} 125.747411703\n",
      "30 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.11662912394210095}\n",
      "31 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "31 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "31 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "31 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "31 {'windowSize': 214, 'nWindows': 2, 'k': 2.1333708760578989} 125.737956254\n",
      "31 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.10881882041201554}\n",
      "32 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "32 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "32 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "32 {'windowSize': 214, 'nWindows': 2, 'k': 2.1411811795879845} 125.729173394\n",
      "32 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.10153154954452946}\n",
      "33 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "33 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "33 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "33 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "33 {'windowSize': 214, 'nWindows': 2, 'k': 2.1484684504554705} 125.721014401\n",
      "33 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.094732285406899902}\n",
      "34 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "34 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "34 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "34 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "34 {'windowSize': 214, 'nWindows': 2, 'k': 2.1552677145931001} 125.713434005\n",
      "34 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.08838834764831846}\n",
      "35 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "35 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "35 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "35 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "35 {'windowSize': 214, 'nWindows': 2, 'k': 2.1616116523516817} 125.706390188\n",
      "35 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.082469244423305915}\n",
      "36 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "36 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "36 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "36 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "36 {'windowSize': 214, 'nWindows': 2, 'k': 2.1675307555766943} 125.699843987\n",
      "36 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.076946525834057283}\n",
      "37 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "37 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "37 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "37 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "37 {'windowSize': 214, 'nWindows': 2, 'k': 2.1730534741659429} 125.693759294\n",
      "37 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.071793647187314708}\n",
      "38 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "38 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "38 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "38 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "38 {'windowSize': 214, 'nWindows': 2, 'k': 2.1782063528126852} 125.688102666\n",
      "38 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.066985841408518335}\n",
      "39 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "39 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "39 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "39 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "39 {'windowSize': 214, 'nWindows': 2, 'k': 2.1830141585914817} 125.682843135\n",
      "39 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.062500000000000014}\n",
      "40 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "40 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "40 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "40 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "40 {'windowSize': 214, 'nWindows': 2, 'k': 2.1875} 125.677952032\n",
      "40 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.058314561971050477}\n",
      "41 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "41 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "41 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "41 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "41 {'windowSize': 214, 'nWindows': 2, 'k': 2.1916854380289497} 125.673402818\n",
      "41 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.054409410206007772}\n",
      "42 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "42 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "42 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "42 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "42 {'windowSize': 214, 'nWindows': 2, 'k': 2.195590589793992} 125.669170927\n",
      "42 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.050765774772264731}\n",
      "43 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "43 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "43 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "43 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "43 {'windowSize': 214, 'nWindows': 2, 'k': 2.1992342252277353} 125.665233617\n",
      "43 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.047366142703449951}\n",
      "44 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "44 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "44 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "44 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "44 {'windowSize': 214, 'nWindows': 2, 'k': 2.2026338572965503} 125.661569832\n",
      "44 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.04419417382415923}\n",
      "45 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "45 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "45 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "45 {'windowSize': 214, 'nWindows': 2, 'k': 2.2058058261758409} 125.658160076\n",
      "45 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.041234622211652958}\n",
      "46 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "46 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "46 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "46 {'windowSize': 214, 'nWindows': 2, 'k': 2.2087653777883469} 125.654986291\n",
      "46 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.038473262917028642}\n",
      "47 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "47 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "47 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "47 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "47 {'windowSize': 214, 'nWindows': 2, 'k': 2.2115267370829712} 125.652031749\n",
      "47 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.035896823593657354}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "48 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "48 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "48 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "48 {'windowSize': 214, 'nWindows': 2, 'k': 2.2141031764063426} 125.649280949\n",
      "48 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.033492920704259167}\n",
      "49 {'windowSize': 213, 'nWindows': 2, 'k': 2.25} 125.597347208\n",
      "49 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "49 {'windowSize': 214, 'nWindows': 1, 'k': 2.25} 128.248672359\n",
      "49 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "49 {'windowSize': 214, 'nWindows': 2, 'k': 2.2165070792957406} 125.646719526\n",
      "49 {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "Best Score  {'windowSize': 214, 'nWindows': 2, 'k': 2.25} 125.611569631\n",
      "change =  {'windowSize': 1, 'nWindows': 1, 'k': 0.031250000000000007}\n"
     ]
    }
   ],
   "source": [
    "# Let's try a simple gradient search on hyper parameters for linear model. \n",
    "nSamples, nFeatures = X_train.shape\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('linear', LinearRegression()) ])\n",
    "\n",
    "params = {'nWindows' : 4, 'windowSize' : 110, 'k' : 1}\n",
    "change = {'nWindows' : 1, 'windowSize' : 50, 'k' : 1.0}\n",
    "niterations = 50\n",
    "learnrate = np.exp(np.log(1/2) / 10)\n",
    "cooling = -1 / 10 * np.log(1/2)\n",
    "currentscore = 2000\n",
    "\n",
    "results = np.empty(0)\n",
    "param_results = []\n",
    "for i in range(niterations):\n",
    "    for key in change:\n",
    "        for scale in np.arange(-1, 3, 2):\n",
    "            params2 = params.copy()\n",
    "            params2[key] += change[key] * scale\n",
    "            if params2[key] > 0 and params2['nWindows'] * params2['windowSize'] < nFeatures:\n",
    "                model.set_params(pre__kw_args = params2)\n",
    "                model.fit(X_train, Y_train)\n",
    "                Y_predict = model.predict(X_valid)\n",
    "                score = smape(Y_predict, Y_valid)\n",
    "                print(i, params2, score)\n",
    "                if score < currentscore:\n",
    "                    params = params2.copy()\n",
    "                    currentscore = score\n",
    "                else: # Do simulated annealing\n",
    "                    jump = np.exp((currentscore - score) * cooling)\n",
    "                    if np.random.rand() < jump:\n",
    "                        params = params2.copy()\n",
    "                        currentscore = score\n",
    "            results = np.hstack((results, currentscore))\n",
    "            param_results.append(params)\n",
    "        change[key] *= learnrate\n",
    "        if key != 'k':\n",
    "            change[key] = np.amax([int(change[key]), 1])\n",
    "                \n",
    "    print('Best Score ', params, currentscore)\n",
    "    print('change = ', change)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFVCAYAAADCLbfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce1a8a5710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 {'windowSize': 209, 'nWindows': 2, 'k': 2.25} 125.521668694\n"
     ]
    }
   ],
   "source": [
    "plt.plot(results)\n",
    "plt.show()\n",
    "\n",
    "bestindex = np.argmin(results)\n",
    "print(bestindex, param_results[bestindex], results[bestindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(10).reshape(2,-1)[:,-2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2986116822.23651457\n",
      "Iteration 2, loss = 2985294710.36466265\n",
      "Iteration 3, loss = 2983860418.02899408\n",
      "Iteration 4, loss = 2981752043.24776602\n",
      "Iteration 5, loss = 2978894884.63106203\n",
      "Iteration 6, loss = 2975303669.46468353\n",
      "Iteration 7, loss = 2970754240.57777214\n",
      "Iteration 8, loss = 2966027277.52307463\n",
      "Iteration 9, loss = 2960737847.07124281\n",
      "Iteration 10, loss = 2954817614.55259037\n",
      "Iteration 11, loss = 2948600252.53936815\n",
      "Iteration 12, loss = 2941521805.82580853\n",
      "Iteration 13, loss = 2934291175.71326017\n",
      "Iteration 14, loss = 2926852256.65638018\n",
      "Iteration 15, loss = 2918420524.29668665\n",
      "Iteration 16, loss = 2909768845.56676722\n",
      "Iteration 17, loss = 2901366891.69754553\n",
      "Iteration 18, loss = 2892061048.76210308\n",
      "Iteration 19, loss = 2881929905.62242460\n",
      "Iteration 20, loss = 2872091057.54651976\n",
      "Iteration 21, loss = 2861633325.25839281\n",
      "Iteration 22, loss = 2851025564.10757923\n",
      "Iteration 23, loss = 2840394557.68098021\n",
      "Iteration 24, loss = 2829172987.01492739\n",
      "Iteration 25, loss = 2817617070.79492569\n",
      "Iteration 26, loss = 2804994635.45452738\n",
      "Iteration 27, loss = 2791690710.58803749\n",
      "Iteration 28, loss = 2778477906.98877144\n",
      "Iteration 29, loss = 2765468325.96399689\n",
      "Iteration 30, loss = 2751561447.03165150\n",
      "Iteration 31, loss = 2738252686.89062595\n",
      "Iteration 32, loss = 2723532219.93946981\n",
      "Iteration 33, loss = 2709447007.63320446\n",
      "Iteration 34, loss = 2694192915.00500154\n",
      "Iteration 35, loss = 2679434512.23695421\n",
      "Iteration 36, loss = 2664771445.14814186\n",
      "Iteration 37, loss = 2649053287.93716669\n",
      "Iteration 38, loss = 2632570782.52535582\n",
      "Iteration 39, loss = 2616399028.57124567\n",
      "Iteration 40, loss = 2598187594.00318384\n",
      "Iteration 41, loss = 2582155293.32851124\n",
      "Iteration 42, loss = 2563994571.20502663\n",
      "Iteration 43, loss = 2545903951.17913389\n",
      "Iteration 44, loss = 2527736019.01579428\n",
      "Iteration 45, loss = 2510359251.58591270\n",
      "Iteration 46, loss = 2492275551.38175249\n",
      "Iteration 47, loss = 2474208823.60512352\n",
      "Iteration 48, loss = 2455480239.11533785\n",
      "Iteration 49, loss = 2435810265.56974411\n",
      "Iteration 50, loss = 2415770274.68205786\n",
      "Iteration 51, loss = 2395733250.71355629\n",
      "Iteration 52, loss = 2375356659.52046537\n",
      "Iteration 53, loss = 2356377101.73307562\n",
      "Iteration 54, loss = 2335021131.74552822\n",
      "Iteration 55, loss = 2314762837.05399942\n",
      "Iteration 56, loss = 2294700399.95999146\n",
      "Iteration 57, loss = 2274217684.69977427\n",
      "Iteration 58, loss = 2252876259.41250515\n",
      "Iteration 59, loss = 2230956506.81188726\n",
      "Iteration 60, loss = 2210537238.27639008\n",
      "Iteration 61, loss = 2189583167.93782282\n",
      "Iteration 62, loss = 2168218774.61551380\n",
      "Iteration 63, loss = 2145478621.52656531\n",
      "Iteration 64, loss = 2123636379.02058649\n",
      "Iteration 65, loss = 2101952904.50573921\n",
      "Iteration 66, loss = 2079564401.93850660\n",
      "Iteration 67, loss = 2056212758.14553928\n",
      "Iteration 68, loss = 2034119414.01157045\n",
      "Iteration 69, loss = 2010534374.97731328\n",
      "Iteration 70, loss = 1986915379.82062984\n",
      "Iteration 71, loss = 1964498220.77574897\n",
      "Iteration 72, loss = 1940797944.15229511\n",
      "Iteration 73, loss = 1918229470.23674202\n",
      "Iteration 74, loss = 1893204663.12640476\n",
      "Iteration 75, loss = 1870649220.47999454\n",
      "Iteration 76, loss = 1846006945.11751604\n",
      "Iteration 77, loss = 1822543422.97093654\n",
      "Iteration 78, loss = 1799793509.99995303\n",
      "Iteration 79, loss = 1776581967.06226659\n",
      "Iteration 80, loss = 1752523979.54442787\n",
      "Iteration 81, loss = 1728150141.17871380\n",
      "Iteration 82, loss = 1703677473.08896708\n",
      "Iteration 83, loss = 1681194374.48931503\n",
      "Iteration 84, loss = 1657836813.21517372\n",
      "Iteration 85, loss = 1633307280.37277603\n",
      "Iteration 86, loss = 1608139886.88733125\n",
      "Iteration 87, loss = 1583397110.56042361\n",
      "Iteration 88, loss = 1560282439.73925471\n",
      "Iteration 89, loss = 1536545354.30183601\n",
      "Iteration 90, loss = 1512543025.70448995\n",
      "Iteration 91, loss = 1487799852.36309910\n",
      "Iteration 92, loss = 1463451254.83175802\n",
      "Iteration 93, loss = 1440049748.47565436\n",
      "Iteration 94, loss = 1416069725.44580388\n",
      "Iteration 95, loss = 1391799919.76773381\n",
      "Iteration 96, loss = 1367357280.18156028\n",
      "Iteration 97, loss = 1344998386.90798211\n",
      "Iteration 98, loss = 1320368675.15813279\n",
      "Iteration 99, loss = 1295733742.40503144\n",
      "Iteration 100, loss = 1272118981.15449929\n",
      "Iteration 101, loss = 1249642482.72693396\n",
      "Iteration 102, loss = 1225416605.04654789\n",
      "Iteration 103, loss = 1202922075.07838058\n",
      "Iteration 104, loss = 1179354172.75665736\n",
      "Iteration 105, loss = 1156224537.12192869\n",
      "Iteration 106, loss = 1134214757.66729760\n",
      "Iteration 107, loss = 1110706391.82789993\n",
      "Iteration 108, loss = 1088219381.83801627\n",
      "Iteration 109, loss = 1065711066.04432762\n",
      "Iteration 110, loss = 1044021005.77062106\n",
      "Iteration 111, loss = 1022940826.42638683\n",
      "Iteration 112, loss = 1001280727.74505639\n",
      "Iteration 113, loss = 978299837.92410600\n",
      "Iteration 114, loss = 957762550.46380198\n",
      "Iteration 115, loss = 935697057.95292580\n",
      "Iteration 116, loss = 913245280.65141904\n",
      "Iteration 117, loss = 891185746.40122294\n",
      "Iteration 118, loss = 871316997.96013236\n",
      "Iteration 119, loss = 850147201.08943522\n",
      "Iteration 120, loss = 830908413.78816175\n",
      "Iteration 121, loss = 811014732.12396681\n",
      "Iteration 122, loss = 791602867.12193000\n",
      "Iteration 123, loss = 770793386.53067625\n",
      "Iteration 124, loss = 751951037.57123268\n",
      "Iteration 125, loss = 733716359.82036245\n",
      "Iteration 126, loss = 713680623.78161693\n",
      "Iteration 127, loss = 695998030.91693544\n",
      "Iteration 128, loss = 678489175.07836676\n",
      "Iteration 129, loss = 660919761.61081433\n",
      "Iteration 130, loss = 642636066.13582361\n",
      "Iteration 131, loss = 625607232.12614572\n",
      "Iteration 132, loss = 609023787.79911935\n",
      "Iteration 133, loss = 591254564.69445360\n",
      "Iteration 134, loss = 574343841.28815567\n",
      "Iteration 135, loss = 557558078.12940252\n",
      "Iteration 136, loss = 541123121.83277249\n",
      "Iteration 137, loss = 526321794.29648060\n",
      "Iteration 138, loss = 510602136.95602661\n",
      "Iteration 139, loss = 496713547.03216451\n",
      "Iteration 140, loss = 481696585.41163397\n",
      "Iteration 141, loss = 468383627.04923213\n",
      "Iteration 142, loss = 454384125.86011428\n",
      "Iteration 143, loss = 440065741.91927969\n",
      "Iteration 144, loss = 428165234.73326141\n",
      "Iteration 145, loss = 415123103.16062725\n",
      "Iteration 146, loss = 403675541.80816293\n",
      "Iteration 147, loss = 390815811.01484621\n",
      "Iteration 148, loss = 379047858.01926857\n",
      "Iteration 149, loss = 368679643.08274150\n",
      "Iteration 150, loss = 357157588.03208417\n",
      "Iteration 151, loss = 346135474.67255646\n",
      "Iteration 152, loss = 335930868.28105426\n",
      "Iteration 153, loss = 326689447.33517969\n",
      "Iteration 154, loss = 316694557.27797669\n",
      "Iteration 155, loss = 309170416.92882615\n",
      "Iteration 156, loss = 300531472.16316152\n",
      "Iteration 157, loss = 292944187.47947019\n",
      "Iteration 158, loss = 283988104.77983433\n",
      "Iteration 159, loss = 276621147.79074132\n",
      "Iteration 160, loss = 269691995.47853875\n",
      "Iteration 161, loss = 261925911.40949926\n",
      "Iteration 162, loss = 255686122.53513521\n",
      "Iteration 163, loss = 249084763.51616541\n",
      "Iteration 164, loss = 242890205.60140264\n",
      "Iteration 165, loss = 237332564.39851519\n",
      "Iteration 166, loss = 232371329.87434414\n",
      "Iteration 167, loss = 227113132.37121922\n",
      "Iteration 168, loss = 221921420.54493985\n",
      "Iteration 169, loss = 217994598.34731179\n",
      "Iteration 170, loss = 214061383.38398263\n",
      "Iteration 171, loss = 210215513.74842530\n",
      "Iteration 172, loss = 206717279.44152713\n",
      "Iteration 173, loss = 202939512.32143915\n",
      "Iteration 174, loss = 199793822.56275746\n",
      "Iteration 175, loss = 196590191.00705716\n",
      "Iteration 176, loss = 192347591.85716984\n",
      "Iteration 177, loss = 191112683.95792758\n",
      "Iteration 178, loss = 188323529.51911312\n",
      "Iteration 179, loss = 186592524.92264190\n",
      "Iteration 180, loss = 184454618.80623689\n",
      "Iteration 181, loss = 182690025.92554802\n",
      "Iteration 182, loss = 181532283.19484797\n",
      "Iteration 183, loss = 179470986.32763603\n",
      "Iteration 184, loss = 178235122.15593508\n",
      "Iteration 185, loss = 176940158.14913490\n",
      "Iteration 186, loss = 175219424.89177603\n",
      "Iteration 187, loss = 174226759.34397051\n",
      "Iteration 188, loss = 172240661.50815341\n",
      "Iteration 189, loss = 170164178.00955731\n",
      "Iteration 190, loss = 171100937.09938490\n",
      "Iteration 191, loss = 170379285.91012964\n",
      "Iteration 192, loss = 169650996.61755711\n",
      "Iteration 193, loss = 168897200.36853558\n",
      "Iteration 194, loss = 168229895.30760458\n",
      "Iteration 195, loss = 167188797.39060935\n",
      "Iteration 196, loss = 167160807.74487388\n",
      "Iteration 197, loss = 163939466.45825046\n",
      "Iteration 198, loss = 165233192.55077285\n",
      "Iteration 199, loss = 165656444.76869097\n",
      "Iteration 200, loss = 165099120.31954369\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7138313860.86401558\n",
      "Iteration 2, loss = 7132593411.48067760\n",
      "Iteration 3, loss = 7127232514.44857502\n",
      "Iteration 4, loss = 7119085876.33787441\n",
      "Iteration 5, loss = 7109251619.39457989\n",
      "Iteration 6, loss = 7097666950.29242325\n",
      "Iteration 7, loss = 7084160684.62523270\n",
      "Iteration 8, loss = 7069568831.42622566\n",
      "Iteration 9, loss = 7053820118.46400356\n",
      "Iteration 10, loss = 7035971757.66490078\n",
      "Iteration 11, loss = 7017460273.95276356\n",
      "Iteration 12, loss = 6997075535.56021118\n",
      "Iteration 13, loss = 6976714474.76372147\n",
      "Iteration 14, loss = 6954465599.17945766\n",
      "Iteration 15, loss = 6930429452.39121151\n",
      "Iteration 16, loss = 6905740894.51911449\n",
      "Iteration 17, loss = 6884488739.52881050\n",
      "Iteration 18, loss = 6854241652.83516502\n",
      "Iteration 19, loss = 6826102953.50436687\n",
      "Iteration 20, loss = 6797358299.29878616\n",
      "Iteration 21, loss = 6769479261.00911045\n",
      "Iteration 22, loss = 6740598300.73690605\n",
      "Iteration 23, loss = 6706563495.77351284\n",
      "Iteration 24, loss = 6672838244.56517601\n",
      "Iteration 25, loss = 6639176328.00432110\n",
      "Iteration 26, loss = 6603326185.93286514\n",
      "Iteration 27, loss = 6567059227.49410057\n",
      "Iteration 28, loss = 6531648327.64995384\n",
      "Iteration 29, loss = 6496406612.02924919\n",
      "Iteration 30, loss = 6458863269.68883610\n",
      "Iteration 31, loss = 6420524633.46163464\n",
      "Iteration 32, loss = 6380471328.14257240\n",
      "Iteration 33, loss = 6338457033.95076466\n",
      "Iteration 34, loss = 6298198807.04700661\n",
      "Iteration 35, loss = 6255931828.91680908\n",
      "Iteration 36, loss = 6216609602.28520489\n",
      "Iteration 37, loss = 6171278138.42434883\n",
      "Iteration 38, loss = 6129311509.97016525\n",
      "Iteration 39, loss = 6083786019.53977299\n",
      "Iteration 40, loss = 6035467377.14480495\n",
      "Iteration 41, loss = 5989178284.21042442\n",
      "Iteration 42, loss = 5940292838.95400906\n",
      "Iteration 43, loss = 5891900588.37593555\n",
      "Iteration 44, loss = 5842970419.00181675\n",
      "Iteration 45, loss = 5792779251.74347210\n",
      "Iteration 46, loss = 5743249127.52559280\n",
      "Iteration 47, loss = 5692338420.76102543\n",
      "Iteration 48, loss = 5639041075.71759129\n",
      "Iteration 49, loss = 5585444512.92531872\n",
      "Iteration 50, loss = 5535104009.05715752\n",
      "Iteration 51, loss = 5482499914.15453911\n",
      "Iteration 52, loss = 5432588269.86182308\n",
      "Iteration 53, loss = 5382487347.18210506\n",
      "Iteration 54, loss = 5320244768.06114006\n",
      "Iteration 55, loss = 5264578519.96348381\n",
      "Iteration 56, loss = 5208206711.67715263\n",
      "Iteration 57, loss = 5150998122.09233093\n",
      "Iteration 58, loss = 5094839537.74045086\n",
      "Iteration 59, loss = 5037801336.30466557\n",
      "Iteration 60, loss = 4979175772.33065414\n",
      "Iteration 61, loss = 4920308830.02831268\n",
      "Iteration 62, loss = 4861682290.72204971\n",
      "Iteration 63, loss = 4802721077.91489601\n",
      "Iteration 64, loss = 4743105737.27264595\n",
      "Iteration 65, loss = 4680371812.75674915\n",
      "Iteration 66, loss = 4618983883.41694260\n",
      "Iteration 67, loss = 4569268976.85864735\n",
      "Iteration 68, loss = 4508677317.16001511\n",
      "Iteration 69, loss = 4440072564.91175747\n",
      "Iteration 70, loss = 4379111112.26551151\n",
      "Iteration 71, loss = 4319489816.67786884\n",
      "Iteration 72, loss = 4255496344.58978271\n",
      "Iteration 73, loss = 4192282093.67954874\n",
      "Iteration 74, loss = 4126809469.24378920\n",
      "Iteration 75, loss = 4063662037.66704273\n",
      "Iteration 76, loss = 3998279676.51185846\n",
      "Iteration 77, loss = 3934971600.62887430\n",
      "Iteration 78, loss = 3871684373.58925724\n",
      "Iteration 79, loss = 3810784171.76129484\n",
      "Iteration 80, loss = 3748127130.42044544\n",
      "Iteration 81, loss = 3682753198.19728708\n",
      "Iteration 82, loss = 3615134270.18782091\n",
      "Iteration 83, loss = 3561169679.07117224\n",
      "Iteration 84, loss = 3486275223.46767282\n",
      "Iteration 85, loss = 3422135029.96555328\n",
      "Iteration 86, loss = 3359455824.08864927\n",
      "Iteration 87, loss = 3296952659.53207779\n",
      "Iteration 88, loss = 3232506731.97555780\n",
      "Iteration 89, loss = 3167623886.48839474\n",
      "Iteration 90, loss = 3098720671.98030329\n",
      "Iteration 91, loss = 3041218787.68979120\n",
      "Iteration 92, loss = 2973686152.68583632\n",
      "Iteration 93, loss = 2906599790.16649199\n",
      "Iteration 94, loss = 2840832345.79843140\n",
      "Iteration 95, loss = 2777802410.51296043\n",
      "Iteration 96, loss = 2715728426.88785267\n",
      "Iteration 97, loss = 2653613901.42084885\n",
      "Iteration 98, loss = 2589485198.23094082\n",
      "Iteration 99, loss = 2526373949.42776871\n",
      "Iteration 100, loss = 2473296667.02910948\n",
      "Iteration 101, loss = 2403914144.91281700\n",
      "Iteration 102, loss = 2340683208.20111513\n",
      "Iteration 103, loss = 2279581720.33809900\n",
      "Iteration 104, loss = 2223057856.68345737\n",
      "Iteration 105, loss = 2162946750.13201714\n",
      "Iteration 106, loss = 2103601200.71676040\n",
      "Iteration 107, loss = 2048369089.46605396\n",
      "Iteration 108, loss = 1987098086.56481862\n",
      "Iteration 109, loss = 1927988224.65750623\n",
      "Iteration 110, loss = 1868782670.99125910\n",
      "Iteration 111, loss = 1809745605.40545392\n",
      "Iteration 112, loss = 1750064238.81388974\n",
      "Iteration 113, loss = 1695525770.77036834\n",
      "Iteration 114, loss = 1638582572.15948701\n",
      "Iteration 115, loss = 1583426706.79543328\n",
      "Iteration 116, loss = 1531057741.22315001\n",
      "Iteration 117, loss = 1486499481.48106074\n",
      "Iteration 118, loss = 1429657609.64931083\n",
      "Iteration 119, loss = 1378146178.20611596\n",
      "Iteration 120, loss = 1327469056.52327442\n",
      "Iteration 121, loss = 1277269827.31928301\n",
      "Iteration 122, loss = 1232481184.87034154\n",
      "Iteration 123, loss = 1176104782.00960135\n",
      "Iteration 124, loss = 1127199044.88964248\n",
      "Iteration 125, loss = 1079286936.88065195\n",
      "Iteration 126, loss = 1033987412.08916700\n",
      "Iteration 127, loss = 988011518.13926458\n",
      "Iteration 128, loss = 944090619.45757973\n",
      "Iteration 129, loss = 900661941.67449892\n",
      "Iteration 130, loss = 862426518.48097527\n",
      "Iteration 131, loss = 818081519.13359237\n",
      "Iteration 132, loss = 776816664.13125288\n",
      "Iteration 133, loss = 737528052.32366967\n",
      "Iteration 134, loss = 700208926.83402681\n",
      "Iteration 135, loss = 663690515.37324464\n",
      "Iteration 136, loss = 627715556.27957225\n",
      "Iteration 137, loss = 593103924.03155911\n",
      "Iteration 138, loss = 559628305.67075098\n",
      "Iteration 139, loss = 528247685.99848276\n",
      "Iteration 140, loss = 497486800.79886878\n",
      "Iteration 141, loss = 467327556.18154407\n",
      "Iteration 142, loss = 441571945.83020401\n",
      "Iteration 143, loss = 412772139.20619136\n",
      "Iteration 144, loss = 386934125.40892601\n",
      "Iteration 145, loss = 362831417.97076678\n",
      "Iteration 146, loss = 339525164.62741476\n",
      "Iteration 147, loss = 317620983.87771684\n",
      "Iteration 148, loss = 296835301.28331697\n",
      "Iteration 149, loss = 277024575.98133904\n",
      "Iteration 150, loss = 258624834.46077707\n",
      "Iteration 151, loss = 241884009.68000087\n",
      "Iteration 152, loss = 226833675.37496334\n",
      "Iteration 153, loss = 212610823.68229276\n",
      "Iteration 154, loss = 199416144.89920390\n",
      "Iteration 155, loss = 186883902.22870302\n",
      "Iteration 156, loss = 176496954.92005903\n",
      "Iteration 157, loss = 166879926.72064433\n",
      "Iteration 158, loss = 158507987.91846144\n",
      "Iteration 159, loss = 150882154.62437934\n",
      "Iteration 160, loss = 143717833.12083921\n",
      "Iteration 161, loss = 137679332.87940434\n",
      "Iteration 162, loss = 132011942.23392020\n",
      "Iteration 163, loss = 127868752.02324034\n",
      "Iteration 164, loss = 123977673.30041198\n",
      "Iteration 165, loss = 120448080.39750250\n",
      "Iteration 166, loss = 117418529.98107623\n",
      "Iteration 167, loss = 115154920.61743139\n",
      "Iteration 168, loss = 112886342.79378183\n",
      "Iteration 169, loss = 110743709.01260243\n",
      "Iteration 170, loss = 109275968.00833476\n",
      "Iteration 171, loss = 108223106.68247372\n",
      "Iteration 172, loss = 106835700.60162492\n",
      "Iteration 173, loss = 105710083.66925701\n",
      "Iteration 174, loss = 105083006.62647359\n",
      "Iteration 175, loss = 103988219.38252626\n",
      "Iteration 176, loss = 103257269.81354678\n",
      "Iteration 177, loss = 102914950.25598495\n",
      "Iteration 178, loss = 102517015.03814018\n",
      "Iteration 179, loss = 102042511.52746153\n",
      "Iteration 180, loss = 101646827.19355132\n",
      "Iteration 181, loss = 101347606.66430414\n",
      "Iteration 182, loss = 100995494.81487378\n",
      "Iteration 183, loss = 100888694.01995088\n",
      "Iteration 184, loss = 100438378.59771822\n",
      "Iteration 185, loss = 100259149.22969638\n",
      "Iteration 186, loss = 98092845.32776175\n",
      "Iteration 187, loss = 100300242.21097741\n",
      "Iteration 188, loss = 99036369.89236443\n",
      "Iteration 189, loss = 100070728.50536059\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 4564629369.62396336\n",
      "Iteration 2, loss = 4563087797.70339394\n",
      "Iteration 3, loss = 4560879576.99619198\n",
      "Iteration 4, loss = 4557694686.56111622\n",
      "Iteration 5, loss = 4554031420.82836437\n",
      "Iteration 6, loss = 4549347572.23984718\n",
      "Iteration 7, loss = 4543981391.54824066\n",
      "Iteration 8, loss = 4538056946.84717846\n",
      "Iteration 9, loss = 4531104985.08899975\n",
      "Iteration 10, loss = 4523698661.97896862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, loss = 4515839935.50704670\n",
      "Iteration 12, loss = 4507028834.99466610\n",
      "Iteration 13, loss = 4497890361.20531082\n",
      "Iteration 14, loss = 4488256645.51621723\n",
      "Iteration 15, loss = 4477728122.85527039\n",
      "Iteration 16, loss = 4466666864.07724571\n",
      "Iteration 17, loss = 4455638792.81875038\n",
      "Iteration 18, loss = 4444093343.34141064\n",
      "Iteration 19, loss = 4432185058.17986298\n",
      "Iteration 20, loss = 4419622745.95320034\n",
      "Iteration 21, loss = 4406870683.68307972\n",
      "Iteration 22, loss = 4392934582.10162163\n",
      "Iteration 23, loss = 4379765749.84084034\n",
      "Iteration 24, loss = 4364732298.27262974\n",
      "Iteration 25, loss = 4349741137.65052605\n",
      "Iteration 26, loss = 4335163984.35130787\n",
      "Iteration 27, loss = 4319148845.85030842\n",
      "Iteration 28, loss = 4302154623.95718861\n",
      "Iteration 29, loss = 4285552150.47170639\n",
      "Iteration 30, loss = 4268620123.08406544\n",
      "Iteration 31, loss = 4251524217.25666904\n",
      "Iteration 32, loss = 4234096267.67297935\n",
      "Iteration 33, loss = 4215144927.71070099\n",
      "Iteration 34, loss = 4195727753.87424326\n",
      "Iteration 35, loss = 4177426068.40554810\n",
      "Iteration 36, loss = 4158104912.62039328\n",
      "Iteration 37, loss = 4137422563.63228941\n",
      "Iteration 38, loss = 4116894962.09116364\n",
      "Iteration 39, loss = 4096826204.52652979\n",
      "Iteration 40, loss = 4076156084.98323679\n",
      "Iteration 41, loss = 4053491080.60940886\n",
      "Iteration 42, loss = 4031804955.63629246\n",
      "Iteration 43, loss = 4009027407.13394642\n",
      "Iteration 44, loss = 3986498258.99206305\n",
      "Iteration 45, loss = 3963699051.33998919\n",
      "Iteration 46, loss = 3939163361.12428284\n",
      "Iteration 47, loss = 3914997621.68198347\n",
      "Iteration 48, loss = 3892384675.49060392\n",
      "Iteration 49, loss = 3868165023.26159906\n",
      "Iteration 50, loss = 3843255494.87907267\n",
      "Iteration 51, loss = 3817023829.04696226\n",
      "Iteration 52, loss = 3791646874.92856407\n",
      "Iteration 53, loss = 3765888788.21707344\n",
      "Iteration 54, loss = 3740417648.53559065\n",
      "Iteration 55, loss = 3712781027.58943844\n",
      "Iteration 56, loss = 3686124510.01773500\n",
      "Iteration 57, loss = 3659685125.96019077\n",
      "Iteration 58, loss = 3632519359.74520063\n",
      "Iteration 59, loss = 3604698611.45579386\n",
      "Iteration 60, loss = 3576698003.65890074\n",
      "Iteration 61, loss = 3547103579.19966841\n",
      "Iteration 62, loss = 3519200816.10590124\n",
      "Iteration 63, loss = 3490408980.36968279\n",
      "Iteration 64, loss = 3461715976.13062954\n",
      "Iteration 65, loss = 3433845385.62086248\n",
      "Iteration 66, loss = 3404225522.81520844\n",
      "Iteration 67, loss = 3374638359.86770821\n",
      "Iteration 68, loss = 3342859993.43343639\n",
      "Iteration 69, loss = 3313008679.60605097\n",
      "Iteration 70, loss = 3282317377.39801073\n",
      "Iteration 71, loss = 3251573730.67356253\n",
      "Iteration 72, loss = 3220982868.57165623\n",
      "Iteration 73, loss = 3189530675.66409159\n",
      "Iteration 74, loss = 3160375965.91693163\n",
      "Iteration 75, loss = 3128437654.45701933\n",
      "Iteration 76, loss = 3095542510.06494856\n",
      "Iteration 77, loss = 3065334702.66829062\n",
      "Iteration 78, loss = 3033347083.96120644\n",
      "Iteration 79, loss = 3000056813.15255213\n",
      "Iteration 80, loss = 2968410202.73599195\n",
      "Iteration 81, loss = 2935538111.31481457\n",
      "Iteration 82, loss = 2903265599.71738243\n",
      "Iteration 83, loss = 2871179318.00230503\n",
      "Iteration 84, loss = 2838351773.02988720\n",
      "Iteration 85, loss = 2803989703.17601681\n",
      "Iteration 86, loss = 2772145147.34264135\n",
      "Iteration 87, loss = 2739503118.56956339\n",
      "Iteration 88, loss = 2706421730.98674536\n",
      "Iteration 89, loss = 2671419905.62719488\n",
      "Iteration 90, loss = 2636979302.37912989\n",
      "Iteration 91, loss = 2604290228.37394428\n",
      "Iteration 92, loss = 2569194681.43970633\n",
      "Iteration 93, loss = 2534544163.33305359\n",
      "Iteration 94, loss = 2499900758.96299410\n",
      "Iteration 95, loss = 2467117169.04104853\n",
      "Iteration 96, loss = 2432094560.60535049\n",
      "Iteration 97, loss = 2397174962.34230804\n",
      "Iteration 98, loss = 2362049371.02600861\n",
      "Iteration 99, loss = 2329793112.80057907\n",
      "Iteration 100, loss = 2295016575.91511202\n",
      "Iteration 101, loss = 2260111651.03273630\n",
      "Iteration 102, loss = 2224737521.74088097\n",
      "Iteration 103, loss = 2189767449.39064169\n",
      "Iteration 104, loss = 2155899878.66878033\n",
      "Iteration 105, loss = 2124907932.85317063\n",
      "Iteration 106, loss = 2092825537.54804683\n",
      "Iteration 107, loss = 2060147860.89292216\n",
      "Iteration 108, loss = 2027376202.95333862\n",
      "Iteration 109, loss = 1994374872.68211436\n",
      "Iteration 110, loss = 1960429156.42968774\n",
      "Iteration 111, loss = 1925224641.04516244\n",
      "Iteration 112, loss = 1891377560.17368221\n",
      "Iteration 113, loss = 1856358222.38109183\n",
      "Iteration 114, loss = 1823484056.03444982\n",
      "Iteration 115, loss = 1791178353.81481433\n",
      "Iteration 116, loss = 1756870521.02829051\n",
      "Iteration 117, loss = 1723802974.28428221\n",
      "Iteration 118, loss = 1689081628.45318413\n",
      "Iteration 119, loss = 1656282979.59852052\n",
      "Iteration 120, loss = 1622408074.04092097\n",
      "Iteration 121, loss = 1589864498.02031350\n",
      "Iteration 122, loss = 1559432725.50531983\n",
      "Iteration 123, loss = 1528631241.07728958\n",
      "Iteration 124, loss = 1497406691.00398540\n",
      "Iteration 125, loss = 1465437638.52640533\n",
      "Iteration 126, loss = 1432138556.63121867\n",
      "Iteration 127, loss = 1400118489.45938444\n",
      "Iteration 128, loss = 1369864887.96646690\n",
      "Iteration 129, loss = 1339678028.42285848\n",
      "Iteration 130, loss = 1308309347.66101980\n",
      "Iteration 131, loss = 1278308840.31380081\n",
      "Iteration 132, loss = 1247366152.15745854\n",
      "Iteration 133, loss = 1217731738.65897036\n",
      "Iteration 134, loss = 1187091275.89910793\n",
      "Iteration 135, loss = 1156263536.76554418\n",
      "Iteration 136, loss = 1127173810.99369192\n",
      "Iteration 137, loss = 1098165196.20496082\n",
      "Iteration 138, loss = 1071165786.21038604\n",
      "Iteration 139, loss = 1044355510.65968192\n",
      "Iteration 140, loss = 1017323142.71067536\n",
      "Iteration 141, loss = 988640651.64083946\n",
      "Iteration 142, loss = 961186504.13498187\n",
      "Iteration 143, loss = 933894430.99014914\n",
      "Iteration 144, loss = 906219325.68825066\n",
      "Iteration 145, loss = 881473688.16449499\n",
      "Iteration 146, loss = 854556251.45519197\n",
      "Iteration 147, loss = 828233051.41360056\n",
      "Iteration 148, loss = 803714262.41543210\n",
      "Iteration 149, loss = 779271128.44778275\n",
      "Iteration 150, loss = 755295751.91060269\n",
      "Iteration 151, loss = 732448225.87331057\n",
      "Iteration 152, loss = 709173143.39694357\n",
      "Iteration 153, loss = 684836339.01269591\n",
      "Iteration 154, loss = 662004304.48092556\n",
      "Iteration 155, loss = 639327630.44951963\n",
      "Iteration 156, loss = 616935144.56820214\n",
      "Iteration 157, loss = 595939925.39470685\n",
      "Iteration 158, loss = 576443272.39611518\n",
      "Iteration 159, loss = 556365348.33315206\n",
      "Iteration 160, loss = 537560485.67569196\n",
      "Iteration 161, loss = 518726741.50088912\n",
      "Iteration 162, loss = 500348399.27821714\n",
      "Iteration 163, loss = 482630766.51620692\n",
      "Iteration 164, loss = 464585912.63307542\n",
      "Iteration 165, loss = 445867740.26487404\n",
      "Iteration 166, loss = 428584933.93950820\n",
      "Iteration 167, loss = 411537633.99121338\n",
      "Iteration 168, loss = 395331681.52947110\n",
      "Iteration 169, loss = 381077829.11289918\n",
      "Iteration 170, loss = 366672843.85294056\n",
      "Iteration 171, loss = 351350601.93660033\n",
      "Iteration 172, loss = 337442854.56775326\n",
      "Iteration 173, loss = 324220128.39866412\n",
      "Iteration 174, loss = 311522351.00153863\n",
      "Iteration 175, loss = 299315215.51062179\n",
      "Iteration 176, loss = 287516358.67013985\n",
      "Iteration 177, loss = 276931118.66747570\n",
      "Iteration 178, loss = 266112603.20049888\n",
      "Iteration 179, loss = 255600924.65609547\n",
      "Iteration 180, loss = 246134653.90353274\n",
      "Iteration 181, loss = 236678187.24808997\n",
      "Iteration 182, loss = 227735877.27614382\n",
      "Iteration 183, loss = 219638125.02435082\n",
      "Iteration 184, loss = 212138790.81005886\n",
      "Iteration 185, loss = 205184136.38206518\n",
      "Iteration 186, loss = 198574773.15797019\n",
      "Iteration 187, loss = 192172576.40318018\n",
      "Iteration 188, loss = 185399859.11663646\n",
      "Iteration 189, loss = 179706195.12701422\n",
      "Iteration 190, loss = 174175265.62845394\n",
      "Iteration 191, loss = 169880586.99922699\n",
      "Iteration 192, loss = 165134381.97229892\n",
      "Iteration 193, loss = 160947303.27328265\n",
      "Iteration 194, loss = 157300179.09800684\n",
      "Iteration 195, loss = 153535784.46172744\n",
      "Iteration 196, loss = 150243481.92456558\n",
      "Iteration 197, loss = 146720884.74544913\n",
      "Iteration 198, loss = 144246248.67762691\n",
      "Iteration 199, loss = 141634048.29686311\n",
      "Iteration 200, loss = 138977421.84060633\n",
      "Iteration 201, loss = 136439406.59354460\n",
      "Iteration 202, loss = 134371109.08674505\n",
      "Iteration 203, loss = 131696421.29788041\n",
      "Iteration 204, loss = 131334868.90922423\n",
      "Iteration 205, loss = 129684758.51686433\n",
      "Iteration 206, loss = 128857268.28778990\n",
      "Iteration 207, loss = 127454615.55627809\n",
      "Iteration 208, loss = 126100513.73978135\n",
      "Iteration 209, loss = 125726508.50617404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 210, loss = 124293107.01153493\n",
      "Iteration 211, loss = 123757720.29972303\n",
      "Iteration 212, loss = 123177087.88044465\n",
      "Iteration 213, loss = 122274037.48397082\n",
      "Iteration 214, loss = 121895063.83350658\n",
      "Iteration 215, loss = 121592792.29494183\n",
      "Iteration 216, loss = 120986351.49491724\n",
      "Iteration 217, loss = 120547164.14876616\n",
      "Iteration 218, loss = 120183281.58468807\n",
      "Iteration 219, loss = 119906793.21687666\n",
      "Iteration 220, loss = 119220436.58195485\n",
      "Iteration 221, loss = 119111814.03694600\n",
      "Iteration 222, loss = 118651678.02202776\n",
      "Iteration 223, loss = 118690765.69036682\n",
      "Iteration 224, loss = 118605356.52848397\n",
      "Iteration 225, loss = 118134077.45873401\n",
      "Iteration 226, loss = 117764953.84633027\n",
      "Iteration 227, loss = 117711906.82699314\n",
      "Iteration 228, loss = 117775363.73020022\n",
      "Iteration 229, loss = 117405253.27917857\n",
      "Iteration 230, loss = 117436359.95912799\n",
      "Iteration 231, loss = 117092592.84458052\n",
      "Iteration 232, loss = 116916970.32599714\n",
      "Iteration 233, loss = 116873883.16402470\n",
      "Iteration 234, loss = 116851464.55798225\n",
      "Iteration 235, loss = 116640579.22171780\n",
      "Iteration 236, loss = 116443175.57693198\n",
      "Iteration 237, loss = 116571147.24388514\n",
      "Iteration 238, loss = 115856172.25642894\n",
      "Iteration 239, loss = 116536095.19507629\n",
      "Iteration 240, loss = 115933756.82635032\n",
      "Iteration 241, loss = 116650171.12433472\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Cross val score =  109.499692128 +- 3.13884322495\n"
     ]
    }
   ],
   "source": [
    "# Let's just check a simple neural network.\n",
    "\n",
    "model = Pipeline([ ('pre', FunctionTransformer(all_features)),\n",
    "                   ('normalize', StandardScaler()), #with_mean = True, with_std = True)),\n",
    "                   ('neural', MLPRegressor(hidden_layer_sizes = (6), verbose = True, learning_rate_init = 10**-1.9, \n",
    "                                           max_iter = 350)) ]) #, learning_rate = 'adaptive')) ])\n",
    "scores = - cross_val_score(model, X_trainvalid, Y_trainvalid, scoring = smape_scorer)\n",
    "print('Cross val score = ', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
